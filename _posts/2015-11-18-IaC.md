---
layout:     post
title:      Infrastructure as Code - Terraform, Packer, and Puppet
date:       2015-11-18 19:46
type:       post
draft:      true
---

## Introduction

This article is about how to create code to be able to repeatably reproduce an infrastructure that can be used to automatically assign roles to machines through DNS.

This example will use OpenStack as the deployment platform, but with minimal effort it should be possible to modify the Terraform and Packer templates to work with any of their providers such as AWS or GCE.

## Plan

0. build custom base Linux operating system image customized for our environment using Packer
0. build a Puppet master using Terraform and `puppet apply`
0. deploy other core services using roles and profiles defined on the Puppet master with automatic role assignment based on client FQDN

## Naming Scheme

In this example the naming scheme for machines will be `<hostname>.<logical_group>.<location>.<domain>.<tld>`.

This naming scheme paired with a [puppet fact](https://github.com/roobert/puppet-fqdn-data) and hiera config allows us to assign roles to machines that exist in a logical group, or to machines with a specific hostname.

## OpenStack Prerequisites

In order for Packer and Terraform to be able to communicate with OpenStack, some environment variables need to be set. Follow the instructions here: http://docs.openstack.org/cli-reference/content/cli_openrc.html

My infrastructure requires that I assign floating IPs to OpenStack instances, so I've added the following to my OpenStack RC file to avoid having to repeatedly set it in templates:

```bash
export OS_POOL_NAME="ext-net"
```

Ensure that whenever running a Packer or Terraform command, the OpenStack environment variables have been sourced.

## Packer - Building A Base Image

In this example we'll be using the [OpenStack Debian Jessie image](http://cdimage.debian.org/cdimage/openstack/8.2.0/) available from the [Debian OpenStack cdimage repo](http://cdimage.debian.org/cdimage/openstack/).

I've created a repository with a basic packer template along with some assets to customize the base image and run some tasks on first boot that configure the image for my environment.

The repository: [https://github.com/roobert/packer-openstack-basic](https://github.com/roobert/packer-openstack-basic/)

Here's a copy of the main template:

```json
{
  "builders": [{
    "type": "openstack",
    "ssh_username": "debian",
    "image_name": "debian-jessie-basic",
    "source_image": "7361359e-25c5-4fa6-b421-65884ccc0f16",
    "floating_ip_pool": "ext-net",
    "flavor": "m1.medium"
    }
  ],
  "provisioners": [
    {
      "type": "shell",
      "inline": [
        "sudo install -o debian -g debian -d /var/lib/firstboot"
      ]
    },
    {
      "type": "file",
      "source": "assets/",
      "destination": "/var/lib/firstboot/"
    },
    {
      "type": "shell",
      "inline": [
        "sudo mv -v /var/lib/firstboot/firstboot.service /etc/systemd/system/",
        "sudo systemctl enable firstboot"
      ]
    },
    {
      "type": "shell",
      "script": "scripts/openstack-puppet-client.sh",
      "execute_command": "chmod +x {{ .Path }}; {{ .Vars }} sudo -E -S sh '{{ .Path }}'"
    }
  ]
}
```

Things to note:

* Our openstack instances are not directly accessible so a floating IP is assigned for the duration of the build process
* If using a newer or different image, adjust the `source_image_id`

The main purpose of using Packer here is to create an image which has puppet-agent installed, this image can then be used as a base to bootstrap a puppetmaster, and later, puppet clients.

My particular OpenStack environment has a default domain of 'novalocal' set, which I don't want. I've included a systemd init script that runs an init script on first boot which corrects the hosts file and hostname, then deletes itself.

Run packer build:

```
mbp0 /home/rw/git/packer-openstack-basic master ✓ > packer build openstack-basic.json
openstack output will be in this color.

==> openstack: Discovering enabled extensions...
==> openstack: Loading flavor: m1.medium
    openstack: Verified flavor. ID: 3
==> openstack: Creating temporary keypair for this instance...
==> openstack: Launching server...
    openstack: Server ID: 60e85cb5-d7e7-4ce3-843b-4b721b015e54
==> openstack: Waiting for server to become ready...
==> openstack: Creating floating IP...
    openstack: Pool: ext-net
    openstack: Created floating IP: 10.2.134.149
==> openstack: Associating floating IP with server...
    openstack: IP: 10.2.134.149
    openstack: Added floating IP 10.2.134.149 to instance!
==> openstack: Waiting for SSH to become available...
==> openstack: Connected to SSH!
==> openstack: Provisioning with shell script: /tmp/packer-shell980613793
==> openstack: Uploading assets/ => /var/lib/firstboot/
==> openstack: Provisioning with shell script: /tmp/packer-shell720198995
    openstack: ‘/var/lib/firstboot/firstboot.service’ -> ‘/etc/systemd/system/firstboot.service’
    openstack: Created symlink from /etc/systemd/system/multi-user.target.wants/firstboot.service 
      to /etc/systemd/system/firstboot.service.
==> openstack: Provisioning with shell script: scripts/openstack-basic.sh

<puppet output omitted>

==> openstack: Stopping server...
    openstack: Waiting for server to stop...
==> openstack: Creating the image: debian-jessie-basic
    openstack: Image: 04aab810-18cb-42a4-a622-cccc7998483a
==> openstack: Waiting for image to become ready...
==> openstack: Deleted temporary floating IP 10.2.134.149
==> openstack: Terminating the source server...
==> openstack: Deleting temporary keypair...
Build 'openstack' finished.

==> Builds finished. The artifacts of successful builds are:
--> openstack: An image was created: 04aab810-18cb-42a4-a622-cccc7998483a
```

It should now be possible to build an OpenStack instance based on the image 'debian-jessie-basic'.

## Puppetmaster Prerequisites

Create three git repositories, one for r10k, one to act as the code repository, and one to contain the puppet environment, these will contain the three configurable sets of data for the puppetmaster.

### Repository: `r10k`

Create and commit an `r10k.yaml` config file:

```yaml
:cachedir: '/opt/puppetlabs/r10k/cache'

:sources:
  :puppet-systems:
    remote: 'git@<git_server>:puppet/environments'
    basedir: '/etc/puppetlabs/code/environments'
```

### Repository: `puppet-environments`

Create a repository and run the following commands to create a basic production `environment` hierarchy:

```bash
mkdir -p {modules,site/profile/manifests,site/role/manifests,hiera/nodes}
touch hiera/common.yaml
touch site/profile/manifests/base.pp
touch environment.conf
touch Puppetfile
touch site.pp

# basic configuration and example profile
tee > environment.conf << EOF
manifest = site.pp
modulepath = modules:site
EOF

tee > site.pp << EOF
hiera_include('classes')
EOF

tee > hiera/common.yaml << EOF
classes:
 - 'profile::base'

ntp::servers:
  - 0.us.pool.ntp.org
  - 1.us.pool.ntp.org
EOF

tee > Puppetfile << EOF
forge 'forge.puppetlabs.com'

mod 'puppetlabs/ntp', '4.1.0'
mod 'puppetlabs/stdlib'
mod 'puppetlabs/vcsrepo'

mod 'fqdn_data',
  :git => 'https://github.com/roobert/puppet-fqdn-data.git'
EOF

tee > site/profile/manifests/base.pp << EOF
class profile::base {
  class { '::ntp':  }
}
EOF

tee > hiera/nodes/$(facter -p networking.fqdn) << EOF
classes:
  - profile::base
EOF
```

Rename `master` branch to `production` to conform to what puppet expects the main branch to be called.

```
...
```

### Repository: `code`

Create and commit a `hiera.yaml` configuration file that looks something like this:

```yaml
:backends:
  - yaml

:yaml:
  :datadir: "/etc/puppetlabs/code/environments/%{::environment}/hieradata"

:merge_behavior: deeper

:hierarchy:
  # ident defaults - useful for development
  - "ident/%{fqdn_data.ident}"

  # location/logical_group/node defaults
  - "location/%{fqdn_data.location}/%{fqdn_data.logical_group}/%{trusted.certname}"

  #  node defaults
  - "nodes/%{trusted.certname}"

  # location/group defaults
  - "location/%{fqdn_data.location}/%{fqdn_data.logical_group}"

  # logical group defaults
  - "logical_group/%{fqdn_data.logical_group}"

  # location defaults
  - "location/%{fqdn_data.location}"

  # common defaults
  - "common"
```

This hiera config makes it possible to assign a role to a machine based on it's hostname.

For example, you could automatically apply a `mesos-slave` role to a node by creating a node with the FQDN `foo0.mesos-slave0.london0.example.com` and the hiera config file `hieradata/logical_group/mesos-slave0.yaml` with the following contents:

```yaml
classes:
  - role::mesos::slave
```

### Keys

Create an ssh key for each repo and add it to the assets dir:

```bash
ssh-keygen -q -N '' -t rsa -b 4096 -C 'id_rsa-puppetmaster-r10k' \
  -f assets/ssh/id_rsa-puppetmaster-r10k

ssh-keygen -q -N ''-t rsa -b 4096 -C 'id_rsa-puppetmaster-code' \
  -f assets/ssh/id_rsa-puppetmaster-code

ssh-keygen -q -N '' -t rsa -b 4096 -C 'id_rsa-puppetmaster-environments' \
  -f assets/ssh/id_rsa-puppetmaster-environments

ssh-keygen -q -N '' -t rsa -b 4096 -C 'id_rsa-puppetmaster-modules' \
  -f assets/ssh/id_rsa-puppetmaster-environments
```

The fourth key in this list has access to checkout our internal Puppet modules which live on an internal git server and are defined in our `Puppetfile`.

## Building a Puppet Master using TerraForm

Checkout the terraform-puppetmaster repo from here: [https://github.com/roobert/terraform-puppetmaster](https://github.com/roobert/terraform-puppetmaster).

```bash
provider "openstack" {}

resource "openstack_compute_floatingip_v2" "puppet" {}

resource "openstack_compute_instance_v2" "puppet_systems0_example_com" {
  name        = "puppet.systems0.systems0.example.com"
  image_name  = "debian-jessie-basic"
  flavor_id   = "m1.medium"
  floating_ip = "${openstack_compute_floatingip_v2.puppet.address}"
  key_pair    = "openstack"
}
```

Change the domain in the file as appropriate.

Optionally change the `key_pair` value to an existing key in OpenStack 'Access and Security'. I prefer to have a separate key for OpenStack, generate a passphraseless key by running the following:

```
ssh-keygen -t rsa -b 4096 -C 'id_rsa-openstack' -f ~/.ssh/id_rsa-openstack -q -N ""
```

Load the key into your `ssh-agent`.

```
ssh-add ~/.ssh/id_rsa-openstack
```

Now upload the public key to OpenStack by navigating to the 'Key Pairs' page under the 'Access & Security' menu under 'Compute' for your project.

Run `terraform plan` and `terraform apply`:

```
mbp0 /home/rw/git/terraform-puppetmaster master ✓ > terraform plan -out terraform.tfplan
Refreshing Terraform state prior to plan...


The Terraform execution plan has been generated and is shown below.
Resources are shown in alphabetical order for quick scanning. Green resources
will be created (or destroyed and then created if an existing resource
exists), yellow resources are being changed in-place, and red resources
will be destroyed.

Your plan was also saved to the path below. Call the "apply" subcommand
with this plan file and Terraform will exactly execute this execution
plan.

Path: terraform.tfplan

+ openstack_compute_floatingip_v2.puppet
    address:     "" => "<computed>"
    fixed_ip:    "" => "<computed>"
    instance_id: "" => "<computed>"
    pool:        "" => "ext-net"
    region:      "" => "your_region"

+ openstack_compute_instance_v2.puppet_systems0_example_com
    access_ip_v4: "" => "<computed>"
    access_ip_v6: "" => "<computed>"
    flavor_id:    "" => "3"
    flavor_name:  "" => "<computed>"
    floating_ip:  "" => "${openstack_compute_floatingip_v2.puppet.address}"
    image_id:     "" => "<computed>"
    image_name:   "" => "debian-jessie-basic"
    key_pair:     "" => "debian"
    name:         "" => "puppet.systems0.example.com"
    network.#:    "" => "<computed>"
    region:       "" => "your_region"


Plan: 2 to add, 0 to change, 0 to destroy.

mbp0 /home/rw/git/terraform-puppetmaster master ✓ > terraform apply terraform.tfplan
openstack_compute_floatingip_v2.puppet: Creating...
  address:     "" => "<computed>"
  fixed_ip:    "" => "<computed>"
  instance_id: "" => "<computed>"
  pool:        "" => "ext-net"
  region:      "" => "your_region"
openstack_compute_floatingip_v2.puppet: Creation complete
openstack_compute_instance_v2.puppet_systems0_example_com: Creating...
  access_ip_v4: "" => "<computed>"
  access_ip_v6: "" => "<computed>"
  flavor_id:    "" => "3"
  flavor_name:  "" => "<computed>"
  floating_ip:  "" => "10.2.134.155"
  image_id:     "" => "<computed>"
  image_name:   "" => "debian-jessie-basic"
  key_pair:     "" => "robw"
  name:         "" => "puppet.systems0.example.com"
  network.#:    "" => "<computed>"
  region:       "" => "brighton"
openstack_compute_instance_v2.puppet_systems0_example_com: Creation complete

Apply complete! Resources: 2 added, 0 changed, 0 destroyed.

The state of your infrastructure has been saved to the path
below. This state is required to modify and destroy your
infrastructure, so keep it safe. To inspect the complete state
use the `terraform show` command.

State path: terraform.tfstate

mbp0 /home/rw/git/terraform-puppetmaster master ✓ > 
```

## Puppet Master Configuration

Login and run `r10k`.

```
ssh puppet
r10k environment deploy -v -p production
```

Run puppet to pickup any base classes for your enivronment:
```
puppet agent --test
```

## Building DNS

